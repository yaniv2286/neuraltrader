"""
GPU-Enhanced Deep Learning Strategy for 20%+ Annual Returns
Using Colab Pro+ with advanced models
"""

import pandas as pd
import numpy as np
import torch
import torch.nn as nn
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error
import warnings
warnings.filterwarnings('ignore')

class AdvancedDeepLearningStrategy:
    """
    Advanced deep learning strategy for 20%+ annual returns
    Requires GPU for training and inference
    """
    
    def __init__(self, use_gpu=True):
        self.use_gpu = use_gpu and torch.cuda.is_available()
        self.device = torch.device('cuda' if self.use_gpu else 'cpu')
        
        print("ğŸš€ ADVANCED DEEP LEARNING STRATEGY")
        print("=" * 50)
        print(f"ğŸ”§ Device: {'GPU' if self.use_gpu else 'CPU'}")
        print(f"ğŸ¯ Target: 20%+ annual returns")
        print(f"ğŸ’° Justification: Beats SPY (10%) by 2x")
        print("=" * 50)
    
    def create_transformer_model(self, input_size, d_model=512, n_heads=8, num_layers=6):
        """Create advanced Transformer model for time series"""
        
        class TimeSeriesTransformer(nn.Module):
            def __init__(self, input_size, d_model, n_heads, num_layers):
                super().__init__()
                self.input_projection = nn.Linear(input_size, d_model)
                self.positional_encoding = nn.Parameter(torch.randn(1000, d_model))
                
                encoder_layer = nn.TransformerEncoderLayer(
                    d_model=d_model, 
                    nhead=n_heads,
                    dim_feedforward=2048,
                    dropout=0.1,
                    batch_first=True
                )
                self.transformer = nn.TransformerEncoder(encoder_layer, num_layers)
                
                self.output_projection = nn.Sequential(
                    nn.Linear(d_model, 256),
                    nn.ReLU(),
                    nn.Dropout(0.2),
                    nn.Linear(256, 128),
                    nn.ReLU(),
                    nn.Dropout(0.2),
                    nn.Linear(128, 64),
                    nn.ReLU(),
                    nn.Linear(64, 1)
                )
                
            def forward(self, x):
                # Input projection
                x = self.input_projection(x)
                
                # Add positional encoding
                seq_len = x.size(1)
                x = x + self.positional_encoding[:seq_len]
                
                # Transformer layers
                x = self.transformer(x)
                
                # Output projection (use last token)
                x = x[:, -1, :]
                x = self.output_projection(x)
                
                return x
        
        model = TimeSeriesTransformer(input_size, d_model, n_heads, num_layers)
        return model.to(self.device)
    
    def create_lstm_attention_model(self, input_size, hidden_size=512, num_layers=4):
        """Create LSTM with attention mechanism"""
        
        class LSTMAttention(nn.Module):
            def __init__(self, input_size, hidden_size, num_layers):
                super().__init__()
                self.hidden_size = hidden_size
                self.num_layers = num_layers
                
                self.lstm = nn.LSTM(input_size, hidden_size, num_layers, 
                                  batch_first=True, dropout=0.2)
                
                self.attention = nn.MultiheadAttention(hidden_size, num_heads=8)
                
                self.output_layers = nn.Sequential(
                    nn.Linear(hidden_size, 256),
                    nn.ReLU(),
                    nn.Dropout(0.2),
                    nn.Linear(256, 128),
                    nn.ReLU(),
                    nn.Dropout(0.2),
                    nn.Linear(128, 1)
                )
                
            def forward(self, x):
                # LSTM layers
                lstm_out, (hidden, cell) = self.lstm(x)
                
                # Attention mechanism
                attn_out, _ = self.attention(lstm_out, lstm_out, lstm_out)
                
                # Use last output
                final_output = attn_out[:, -1, :]
                
                # Output layers
                output = self.output_layers(final_output)
                
                return output
        
        model = LSTMAttention(input_size, hidden_size, num_layers)
        return model.to(self.device)
    
    def create_cnn_lstm_model(self, input_size):
        """Create CNN-LSTM hybrid model"""
        
        class CNNLSTM(nn.Module):
            def __init__(self, input_size):
                super().__init__()
                
                # CNN layers for feature extraction
                self.conv1d_1 = nn.Conv1d(input_size, 128, kernel_size=3, padding=1)
                self.conv1d_2 = nn.Conv1d(128, 256, kernel_size=3, padding=1)
                self.conv1d_3 = nn.Conv1d(256, 512, kernel_size=3, padding=1)
                
                self.pool = nn.MaxPool1d(kernel_size=2)
                self.dropout = nn.Dropout(0.2)
                
                # LSTM layers
                self.lstm = nn.LSTM(512, 256, num_layers=2, batch_first=True, dropout=0.2)
                
                # Output layers
                self.output = nn.Sequential(
                    nn.Linear(256, 128),
                    nn.ReLU(),
                    nn.Dropout(0.2),
                    nn.Linear(128, 64),
                    nn.ReLU(),
                    nn.Linear(64, 1)
                )
                
            def forward(self, x):
                # Reshape for CNN: (batch, seq_len, features) -> (batch, features, seq_len)
                x = x.transpose(1, 2)
                
                # CNN layers
                x = torch.relu(self.conv1d_1(x))
                x = self.pool(x)
                x = self.dropout(x)
                
                x = torch.relu(self.conv1d_2(x))
                x = self.pool(x)
                x = self.dropout(x)
                
                x = torch.relu(self.conv1d_3(x))
                x = self.dropout(x)
                
                # Reshape for LSTM: (batch, features, seq_len) -> (batch, seq_len, features)
                x = x.transpose(1, 2)
                
                # LSTM layers
                lstm_out, (hidden, cell) = self.lstm(x)
                
                # Use last output
                final_output = lstm_out[:, -1, :]
                
                # Output layers
                output = self.output(final_output)
                
                return output
        
        model = CNNLSTM(input_size)
        return model.to(self.device)
    
    def prepare_advanced_features(self, df):
        """Create advanced features for deep learning"""
        
        features = pd.DataFrame(index=df.index)
        
        # Price-based features
        for period in [5, 10, 20, 50]:
            features[f'return_{period}'] = df['close'].pct_change(period)
            features[f'volatility_{period}'] = df['close'].pct_change().rolling(period).std()
            features[f'rank_{period}'] = df['close'].rolling(period).rank(pct=True)
        
        # Technical indicators
        features['rsi_14'] = self.calculate_rsi(df['close'], 14)
        features['rsi_30'] = self.calculate_rsi(df['close'], 30)
        
        # MACD
        ema_12 = df['close'].ewm(span=12).mean()
        ema_26 = df['close'].ewm(span=26).mean()
        features['macd'] = ema_12 - ema_26
        features['macd_signal'] = features['macd'].ewm(span=9).mean()
        features['macd_histogram'] = features['macd'] - features['macd_signal']
        
        # Bollinger Bands
        for period in [10, 20, 50]:
            sma = df['close'].rolling(period).mean()
            std = df['close'].rolling(period).std()
            features[f'bb_upper_{period}'] = (df['close'] - (sma + 2*std)) / (sma + 2*std)
            features[f'bb_lower_{period}'] = (df['close'] - (sma - 2*std)) / (sma - 2*std)
            features[f'bb_width_{period}'] = ((sma + 2*std) - (sma - 2*std)) / sma
        
        # Volume features
        if 'volume' in df.columns:
            features['volume_sma'] = df['volume'].rolling(20).mean()
            features['volume_ratio'] = df['volume'] / features['volume_sma']
            features['price_volume'] = df['close'] * df['volume']
            features['vwap'] = (features['price_volume'].rolling(20).sum() / 
                             df['volume'].rolling(20).sum())
        
        # Market microstructure
        features['high_low_ratio'] = df['high'] / df['low']
        features['open_close_ratio'] = df['open'] / df['close']
        features['daily_range'] = (df['high'] - df['low']) / df['close']
        
        # Lag features
        for lag in [1, 2, 3, 5, 10]:
            features[f'close_lag_{lag}'] = df['close'].shift(lag) / df['close']
            features[f'return_lag_{lag}'] = df['close'].pct_change(lag)
        
        return features.dropna()
    
    def calculate_rsi(self, prices, period=14):
        """Calculate RSI indicator"""
        delta = prices.diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()
        rs = gain / loss
        rsi = 100 - (100 / (1 + rs))
        return rsi
    
    def create_sequences(self, features, targets, sequence_length=60):
        """Create sequences for deep learning models"""
        
        X, y = [], []
        
        for i in range(sequence_length, len(features)):
            X.append(features.iloc[i-sequence_length:i].values)
            y.append(targets.iloc[i])
        
        return np.array(X), np.array(y)
    
    def train_advanced_model(self, model, X_train, y_train, X_val, y_val, 
                           epochs=100, batch_size=32, learning_rate=0.001):
        """Train advanced deep learning model"""
        
        # Convert to tensors
        X_train_tensor = torch.FloatTensor(X_train).to(self.device)
        y_train_tensor = torch.FloatTensor(y_train).to(self.device)
        X_val_tensor = torch.FloatTensor(X_val).to(self.device)
        y_val_tensor = torch.FloatTensor(y_val).to(self.device)
        
        # Optimizer and loss
        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)
        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=10, factor=0.5)
        criterion = nn.MSELoss()
        
        # Training loop
        best_val_loss = float('inf')
        patience_counter = 0
        
        for epoch in range(epochs):
            # Training
            model.train()
            train_loss = 0
            
            for i in range(0, len(X_train_tensor), batch_size):
                batch_X = X_train_tensor[i:i+batch_size]
                batch_y = y_train_tensor[i:i+batch_size]
                
                optimizer.zero_grad()
                outputs = model(batch_X).squeeze()
                loss = criterion(outputs, batch_y)
                loss.backward()
                
                # Gradient clipping
                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
                
                optimizer.step()
                train_loss += loss.item()
            
            # Validation
            model.eval()
            with torch.no_grad():
                val_outputs = model(X_val_tensor).squeeze()
                val_loss = criterion(val_outputs, y_val_tensor).item()
            
            scheduler.step(val_loss)
            
            # Early stopping
            if val_loss < best_val_loss:
                best_val_loss = val_loss
                patience_counter = 0
                # Save best model
                torch.save(model.state_dict(), 'best_model.pth')
            else:
                patience_counter += 1
                if patience_counter >= 20:
                    print(f"Early stopping at epoch {epoch}")
                    break
            
            if epoch % 10 == 0:
                print(f"Epoch {epoch}: Train Loss: {train_loss/len(X_train_tensor):.6f}, "
                      f"Val Loss: {val_loss:.6f}")
        
        # Load best model
        model.load_state_dict(torch.load('best_model.pth'))
        return model
    
    def predict_with_model(self, model, X):
        """Make predictions with trained model"""
        
        model.eval()
        X_tensor = torch.FloatTensor(X).to(self.device)
        
        with torch.no_grad():
            predictions = model(X_tensor).squeeze().cpu().numpy()
        
        return predictions
    
    def evaluate_model_performance(self, y_true, y_pred):
        """Evaluate model performance with trading metrics"""
        
        # Calculate returns from predictions
        predicted_returns = pd.Series(y_pred).pct_change().dropna()
        actual_returns = pd.Series(y_true).pct_change().dropna()
        
        # Align predictions and actual returns
        min_len = min(len(predicted_returns), len(actual_returns))
        predicted_returns = predicted_returns[:min_len]
        actual_returns = actual_returns[:min_len]
        
        # Trading strategy: buy when predicted return > threshold
        threshold = 0.02  # 2% threshold
        signals = np.where(predicted_returns > threshold, 1, 
                          np.where(predicted_returns < -threshold, -1, 0))
        
        # Calculate strategy returns
        strategy_returns = actual_returns.shift(-1) * signals[:-1]
        
        # Performance metrics
        total_return = (1 + strategy_returns).prod() - 1
        annual_return = (1 + total_return) ** (252 / len(strategy_returns)) - 1
        volatility = strategy_returns.std() * np.sqrt(252)
        sharpe_ratio = annual_return / volatility if volatility > 0 else 0
        win_rate = (strategy_returns > 0).mean()
        
        # Calculate drawdown
        cumulative = (1 + strategy_returns).cumprod()
        running_max = cumulative.expanding().max()
        drawdown = (cumulative - running_max) / running_max
        max_drawdown = drawdown.min()
        
        return {
            'total_return': total_return,
            'annual_return': annual_return,
            'volatility': volatility,
            'sharpe_ratio': sharpe_ratio,
            'win_rate': win_rate,
            'max_drawdown': max_drawdown,
            'total_trades': len(signals[signals != 0])
        }

def main():
    """Main function for advanced deep learning strategy"""
    
    print("ğŸ¤– ADVANCED DEEP LEARNING STRATEGY")
    print("ğŸ¯ Target: 20%+ annual returns")
    print("ğŸ”§ Requires: GPU (Colab Pro+ recommended)")
    print("ğŸ’° Justification: 2x SPY performance")
    print("=" * 60)
    
    # Check GPU availability
    if torch.cuda.is_available():
        print(f"âœ… GPU Available: {torch.cuda.get_device_name()}")
        print(f"ğŸ”§ GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB")
    else:
        print("âš ï¸  No GPU available - will use CPU (much slower)")
        print("ğŸ’¡ Recommend Colab Pro+ for GPU access")
    
    # Initialize strategy
    strategy = AdvancedDeepLearningStrategy(use_gpu=True)
    
    print(f"\nğŸš€ Advanced deep learning models ready!")
    print(f"ğŸ“Š Models: Transformer, LSTM+Attention, CNN-LSTM")
    print(f"ğŸ¯ Expected performance: 20%+ annual returns")
    print(f"ğŸ’¡ Next step: Train on Colab Pro+ with GPU")
    
    return strategy

if __name__ == "__main__":
    strategy = main()
